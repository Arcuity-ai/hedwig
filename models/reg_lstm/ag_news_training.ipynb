{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikhail/opt/anaconda3/envs/castor/lib/python3.6/site-packages/torch/package/_directory_reader.py:17: UserWarning: Failed to initialize NumPy: No module named 'numpy.core._multiarray_umath' (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1640811914285/work/torch/csrc/utils/tensor_numpy.cpp:68.)\n",
      "  _dtype_to_storage = {data_type(0).dtype: data_type for data_type in _storages}\n"
     ]
    }
   ],
   "source": [
    "import torch.backends.cudnn\n",
    "\n",
    "import models.args\n",
    "import os\n",
    "\n",
    "def get_arg_parser():\n",
    "    parser = models.args.get_args()\n",
    "\n",
    "    parser.add_argument('--bidirectional', action='store_true')\n",
    "    parser.add_argument('--bottleneck-layer', action='store_true')\n",
    "    parser.add_argument('--num-layers', type=int, default=2)\n",
    "    parser.add_argument('--hidden-dim', type=int, default=256)\n",
    "    parser.add_argument('--mode', type=str, default='static', choices=['rand', 'static', 'non-static'])\n",
    "    parser.add_argument('--dataset', type=str, default='Reuters', choices=['Reuters', 'AAPD', 'IMDB', 'Yelp2014'])\n",
    "    parser.add_argument('--words-dim', type=int, default=300)\n",
    "    parser.add_argument('--embed-dim', type=int, default=300)\n",
    "    parser.add_argument('--epoch-decay', type=int, default=15)\n",
    "    parser.add_argument('--weight-decay', type=float, default=0)\n",
    "\n",
    "    parser.add_argument('--dropout', type=float, default=0.5)\n",
    "    parser.add_argument('--wdrop', type=float, default=0.0, help=\"weight drop\")\n",
    "    parser.add_argument('--beta-ema', type=float, default=0, help=\"temporal averaging\")\n",
    "    parser.add_argument('--embed-droprate', type=float, default=0.0, help=\"embedding dropout\")\n",
    "    parser.add_argument('--tar', type=float, default=0.0, help=\"temporal activation regularization\")\n",
    "    parser.add_argument('--ar', type=float, default=0.0, help=\"activation regularization\")\n",
    "\n",
    "    parser.add_argument('--word-vectors-dir', default=os.path.join(os.pardir, 'hedwig-data', 'embeddings', 'word2vec'))\n",
    "    parser.add_argument('--word-vectors-file', default='GoogleNews-vectors-negative300.txt')\n",
    "    parser.add_argument('--save-path', type=str, default=os.path.join('model_checkpoints', 'reg_lstm'))\n",
    "    parser.add_argument('--resume-snapshot', type=str)\n",
    "    parser.add_argument('--trained-model', type=str)\n",
    "\n",
    "    return parser\n",
    "\n",
    "parser = get_arg_parser()\n",
    "args = parser.parse_args(\n",
    "    [\"--mode=static\", \"--batch-size=32\", \"--lr=0.01\", \"--epochs=30\", \"--bidirectional\", \"--num-layers=1\", \"--hidden-dim=512\",  \"--wdrop=0.1\", \"--embed-droprate=0.2\", \"--dropout=0.5\", \"--beta-ema=0.99\", \"--seed=3435\"]\n",
    ")\n",
    "# __main__.py adds some things to args\n",
    "args.gpu = -1\n",
    "args.cuda = False  # I don't have a GPU\n",
    "args.dataset = \"AG_NEWS\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Process the Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-eb769e692b2b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_iter\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget_class\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mNUM_CLASSES\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m \u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwords_num\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_iter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_vocab\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[0msave_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDATASET_NAME\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/castor/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, attribute_name)\u001B[0m\n\u001B[1;32m    224\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunction\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    225\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 226\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    227\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    228\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__reduce_ex__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from models.reg_lstm.model import RegLSTM\n",
    "import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from common.train import TrainerFactory\n",
    "from common.evaluate import ClassificationEvaluator\n",
    "from torchtext.datasets import AG_NEWS\n",
    "# from torchtext.data import Iterator\n",
    "\n",
    "# copy function from __main__.py because __main__ is not compatible\n",
    "#  with the version of torchtext I use\n",
    "\n",
    "def get_logger():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter('%(levelname)s - %(message)s')\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "    return logger\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "DATASET_NAME = \"AG_NEWS\"\n",
    "NUM_CLASSES = 4\n",
    "IS_MULTILABEL = False\n",
    "\n",
    "# set random seed\n",
    "torch.manual_seed(args.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n",
    "train_iter, test_iter = AG_NEWS(split=('train', 'test'))\n",
    "\n",
    "# train_data_loader = Iterator(train_iter, batch_size=args.batch_size)\n",
    "# test_data_loader = Iterator(test_iter, batch_size=args.batch_size)\n",
    "\n",
    "config = deepcopy(args)\n",
    "config.dataset = train_iter\n",
    "config.target_class = NUM_CLASSES\n",
    "config.words_num = len(train_iter.get_vocab())\n",
    "\n",
    "save_path = os.path.join(args.save_path, DATASET_NAME)\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up and train the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = RegLSTM(config)\n",
    "parameter = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameter, lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "trainer_config = {\n",
    "        'optimizer': optimizer,\n",
    "        'batch_size': args.batch_size,\n",
    "        'log_interval': args.log_every,\n",
    "        'patience': args.patience,\n",
    "        'model_outfile': args.save_path,\n",
    "        'logger': logger,\n",
    "        'is_multilabel': IS_MULTILABEL\n",
    "}\n",
    "\n",
    "train_evaluator = ClassificationEvaluator(AG_NEWS, model, None, train_data_loader, args.batch_size, args.gpu)\n",
    "test_evaluator = ClassificationEvaluator(AG_NEWS, model, None, test_data_loader, args.batch_size, args.gpu)\n",
    "\n",
    "if hasattr(train_evaluator, 'is_multilabel'):\n",
    "        train_evaluator.is_multilabel = IS_MULTILABEL\n",
    "if hasattr(test_evaluator, 'is_multilabel'):\n",
    "    test_evaluator.is_multilabel = IS_MULTILABEL\n",
    "\n",
    "trainer = TrainerFactory.get_trainer(args.dataset, model, None, test_iter, trainer_config, train_evaluator, test_evaluator)\n",
    "\n",
    "# train the model\n",
    "trainer.train(args.epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-14f4b887",
   "language": "python",
   "display_name": "PyCharm (hedwig)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}